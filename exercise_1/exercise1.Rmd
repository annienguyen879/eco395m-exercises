---
title: 'ECO 395 Homework 1:'
author: "Soo Jee Choi, Annie Nguyen, and Tarini Sudhakar"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## 1) Data Visualization: Flights at ABIA

### Introduction

In this section, we are looking at a 2008 dataset that contains information on every commercial flight coming in and out of the Austin-Bergstrom Internationial Airport. We are interested in seeing which cities in the dataset have the highest average departure delays.

### Methods

To explore the data and create visualizations, we first need to import the `tidyverse` and `ggplot2` packages and read the `ABIA.csv` file which contains the data. Since we are also interested in visualizing the data on a geographical map, we will also import the `ggmap` package and read the `airport-codes` files, which contain the latitude and longitude reading of each airport. 

```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(tidyverse)
library(ggmap)
abia <- read.csv("ABIA.csv")
airport_codes <- read.csv("airport-codes.csv")
```

First, the `airport_codes` dataframe is cleaned to exclude closed airports and drop rows with NA's or no available IATA-codes. Then, the `airport_codes` dataframe is joined with `abia` dataframe, so each US airport in our targeted dataframe has a respective value for longitude and latitude.

Then, we calculate the average departure delay from each Origin airport. Airports with the highest departure delays include: Knoxville, TN; Birmingham, AL; Washington, D.C.; Raleigh/Durham, NC; San Antonio, TX; Philadelphia, PA.


```{r}
airport_codes <- airport_codes %>% 
  filter(type != "closed", iata_code != "") %>%
  separate(col = coordinates, into= c("lat", "long"), sep = ",") %>%  
  transform(lat = as.numeric(lat), long = as.numeric(long)) %>% 
  select(iata_code, lat, long) %>% drop_na %>% distinct 

avg_delay <- abia %>% group_by(Origin) %>% 
  summarise(avg_delay_time = mean(DepDelay, na.rm = TRUE)) %>%
  arrange(-avg_delay_time) %>% 
  left_join(airport_codes, by= c("Origin" = "iata_code"))

avg_delay %>% select(Origin, avg_delay_time) %>% head %>%
  knitr::kable(caption = "Top 6 Cities with Highest Departure Delays")
```

We will use a barplot to visualize a larger portion of the dataset, looking at the top 20 cities with the highest departure delays.

From the plot, we see that Knoxville has, on average, significantly higher delays than Birmingham (with departure delays close to 70 minutes for Knoxville and near 40 minutes for Birmingham). In comparison, the average delays for the remaining cities stay below 30 minutes.

```{r}
avg_delay %>% head(20) %>% 
  ggplot(aes(reorder(Origin, avg_delay_time), avg_delay_time)) + 
  geom_bar(stat = "identity", color="white") +   coord_flip() + 
  ggtitle("Top 20 Cities with Highest Departure Delays") + 
  xlab("Origin") + ylab("Average Departure Delays (min)")
```

We will visualize the data for all 53 cities included on the dataset by plotting the points on the US map. This will not only show us average airport delays but also give us a brief look at all of the US cities that flyers can travel to from Austin-Bergstrom Internationial Airport.


```{r}
us_map <- map_data(map = "state")
avg_delay %>% ggplot() + 
  geom_polygon(aes(long, lat, group = group), fill= "white", color="black", data= us_map) + 
  coord_map() + 
  geom_point(aes(long, lat, color = avg_delay_time), size = 2) +
  ggtitle("Average Delay Times Across U.S. Cities")+ 
    scale_color_gradient(low = "orange", high = "navy", name = "Avg. Dep. Delay") + 
  xlab("Longitude") + ylab("Latitude")

```

### Results and Conclusion
Based on the results of the plots, we see that Knoxville and Birmingham experience significantly higher departure delays compared to other cities.

From the data visualization generated in this section, we were able to identify airports that experienced the highest average departure delays. This information can help future flyers know what to expect in terms of departure delays when traveling to Austin.

Of course, this brief data exploration and visualization report comes with its own set of limitations. Departure delays are influenced by holiday rushes and weather conditions, so outliers from unusual weather or from other potential problems may skew results. Furthermore, the dataset only includes observations from 2008 and delays may affect each airport differently on a yearly basis.


## 2) Wrangling the Olympics


### A) What is the 95th percentile of heights for female competitors across all Athletics events (i.e., track and field)?  Note that "sport" is the broad sport (e.g. Athletics) whereas "event" is the specific event (e.g. 100 meter sprint). 

```{r 95 percentile atheltics, message=FALSE, results=FALSE}
library(tidyverse)
olympics_data <- read.csv('olympics_top20.csv')
fem_athletics <- subset(olympics_data, sex=="F" & sport=="Athletics", 
                        select=c(name, sex, sport, height))
quantile(fem_athletics$height, probs = .95)
```

The 95th percentile of heights for female competitors across all Athletics events was obtained by first sub-setting the values in the 'olympics_top20.csv' file to observations with the sex variable equal to "F" and the sport variable equal to "Athletic". Then, the quantile function was used to get the 95th quantile of the height of female track and field ("Athletic") Olympians, which was 183cm.


### B) Which single women's "event" had the greatest variability in competitor's heights across the entire history of the Olympics, as measured by the standard deviation?  

```{r women sd height, message=FALSE}
fem_events <- subset(olympics_data, sex=="F", select=c(name, sex, event, height))
fem_height_sd <- fem_events %>% group_by(event) %>% summarise(sd_height = sd(height)) %>% 
  arrange(desc(sd_height))
fem_height_sd %>% select(event, sd_height) %>% head %>%
  knitr::kable(caption = "Top 6 Single Women's Olympic Events with Greatest Variability 
               in Height")
```

To find which single women's event had the greatest variability in competitor's heights (as measured by the standard deviation), we first subset the original data set to contain only females observations. Then the data was grouped by sporting event, and then the standard deviation of the heights for each sport was calculated. Arranging the results in descending order, we find that Rowing Women's Coxed Fours had the greatest variation in competitor's heights (as measured by the standard deviation) at 10.865490.

[Just in case the question was inquiring about which single player women's event had the greatest variability in competitor heights, the answer would be Swimming Women's 100 metres Butterfly.]

### C) How has the average age of Olympic swimmers changed over time? Does the trend look different for male swimmers relative to female swimmers?  Create a data frame that can allow you to visualize these trends over time, then plot the data with a line graph with separate lines for male and female competitors. Give the plot an informative caption answering the two questions just posed. 


```{r Olympic swimmers graph, warning=FALSE, message=FALSE}

#Obtain Olympic swimmers' data by gender
all_swimmers <- subset(olympics_data, sport=="Swimming", select=c(name, sex, sport, age, year))
male_swimmers <- subset(olympics_data, sex=="M" & sport=="Swimming", select=c(name, sex, sport, age, year))
female_swimmers <- subset(olympics_data, sex=="F" & sport=="Swimming", select=c(name, sex, sport, age, year))

#Group by gender and find mean
all_swimmers_mean <- all_swimmers %>% group_by(year) %>% summarise(all_mean_age = mean(age)) %>% arrange(year)
male_swimmers_mean <- male_swimmers %>% group_by(year) %>% summarise(male_mean_age = mean(age)) %>% arrange(year)
female_swimmers_mean <- female_swimmers %>% group_by(year) %>% summarise(female_mean_age = mean(age)) %>% arrange(year)

#Combine datasets
swimmer_data_merge1 <- merge(all_swimmers_mean, male_swimmers_mean, by="year")
swimmer_data_merge2 <- merge(swimmer_data_merge1, female_swimmers_mean, by="year", all=TRUE)

#Plot graph
ggplot(swimmer_data_merge2, aes(x=year)) + 
  ggtitle("Male vs Female: Mean Average Age of Olympic Swimmers by Year") +
  xlab("Year") + ylab("Mean Age") +              
  geom_line(data=swimmer_data_merge2, aes(y = male_mean_age, color = "Male")) + 
  geom_line(data=swimmer_data_merge2, aes(y = female_mean_age, color = "Female")) + 
  geom_line(data=swimmer_data_merge2, aes(y = all_mean_age, color="Both Genders")) +
  scale_color_manual(name = "Key",values = c("Male" = "tomato", "Female" = "steelblue", "Both Genders"="mediumpurple4")) +
  labs(caption=str_wrap("Average age of Olympic swimmers experiences a sharp rise and fall in the early 1900s, and follows 
  an increasing trend thereafter. The average age of male Olympic swimmers generally trends higher than the average age of 
  female Olympic swimmers. However, the average age of male and female Olympic Swimmers notably converge in 2000.")) 
```

The dataset on average age of Olympic swimmers shows that women did not participate in Olympic swimming competitions from 1900 to 1948, with the exception of 1924. We see the average age of Olympic swimmers started at 18 years old in 1900 and reached a peak in 1912 at 27 years old. The data then follows a decreasing trend reaching the lowest average age of 18.53390 in 1976. Then the data follows an increasing trend in the years that follow, with 23.24211 years old in 2016 being the most recent average Olympic swimmers' age data value available.

We see, in the data available for both genders, that male Olympic swimmers, on average, have consistently been older than female Olympic swimmers. However, in 2000, female Olympic swimmer were, on average, 22.53191 years old while male Olympic swimmers were, on average, 22.49451 years old. Hence, we observe a convergence in the graph of the mean average age of Olympic swimmers in the year 2000. Additionally, the average age of male Olympic swimmers experienced fluctuations in the early 1900s (where data on female Olympic swimmers was not available), notably reaching a peak of 32 years old in 1924. Conversely, the data on female Olympic swimmer shows a general increase in average age over time.


## 3) K-Nearest Neighbors: Cars

Here, we filter the Mercedes S Class vehicles for two trim levels: 350 and 65 AMG. The S350 dataset has 416 observations and the S65 AMG has 292 observations. For both datasets, we split the data into a training and test set in an 80-20 ratio. We will use K-nearest neighbors to build a predictive model for price, using mileage, for the two trim levels. 


```{r echo=FALSE, message=FALSE}
library(rsample)
library(caret)
library(foreach)
library(modelr)

sclass <- read.csv('sclass.csv')

set.seed(1720104007)
```

### Let us look at S-Class 350 first 
``` {r}
#Filter for 350
car350 <- sclass %>%
  filter(trim == 350)

#Split train/test for 350
car350_split = initial_split(car350, prop=0.8)
car350_train = training(car350_split)
car350_test  = testing(car350_split)
```

### What happens if we use K = 2? 
```{r 350k2}
knn_model = knnreg(price ~ mileage, data=car350_train, k = 2) 
knn_pred = function(x) {
  predict(knn_model, newdata=data.frame(mileage=x))
}

p_base = ggplot(data = car350) + 
  geom_point(mapping = aes(x = mileage, y = price), color='darkgrey') + 
  theme_bw(base_size=10) 
p_base + stat_function(fun=knn_pred, color='red', size=1.5, n=1001) + ggtitle("K = 2 (Mercedes S-Class 350)")

modelr::rmse(knn_model, car350_test)

```

We get an RMSE of 11,397.94. 

### What about K = 5?
```{r 350k5}
knn_model = knnreg(price ~ mileage, data=car350_train, k = 5) 
knn_pred = function(x) {
  predict(knn_model, newdata=data.frame(mileage=x))
}

p_base + stat_function(fun=knn_pred, color='red', size=1.5, n=1001) + ggtitle("K = 5 (Mercedes S-Class 350)")

modelr::rmse(knn_model, car350_test)

```
Our RMSE falls to 9894.631. 

### K=10
```{r 350k10}
knn_model = knnreg(price ~ mileage, data=car350_train, k = 10) 
knn_pred = function(x) {
  predict(knn_model, newdata=data.frame(mileage=x))
}

p_base + stat_function(fun=knn_pred, color='red', size=1.5, n=1001) + ggtitle("K = 10 (Mercedes S-Class 350)")


modelr::rmse(knn_model, car350_test)

```

Our RMSE rises slightly to 9906.748. 

### K=20
```{r 350k20}
knn_model = knnreg(price ~ mileage, data=car350_train, k = 20) 
knn_pred = function(x) {
  predict(knn_model, newdata=data.frame(mileage=x))
}

p_base + stat_function(fun=knn_pred, color='red', size=1.5, n=1001) + ggtitle("K = 20 (Mercedes S-Class 350)")


modelr::rmse(knn_model, car350_test)

```
At K = 20, our RMSE is at 9448.855.

And just to see what happens when we have an extremely large K value, let us see the RMSE for 150. 

### K=150
```{r 350k150}
knn_model = knnreg(price ~ mileage, data=car350_train, k = 150) 
knn_pred = function(x) {
  predict(knn_model, newdata=data.frame(mileage=x))
}

p_base + stat_function(fun=knn_pred, color='red', size=1.5, n=1001) + ggtitle("K = 150 (Mercedes S-Class 350)")


modelr::rmse(knn_model, car350_test)
```
It rises to 14902.3. Not a good sign.  

Let us look at how our RMSE behaves for different values of K and identify where it bottoms out (since K = 150 was clearly not it). 

### What is our RMSE against different values of K?

```{r fig.align='center', message=FALSE, warning=FALSE}

#Split train/test for 350
car350_split = initial_split(car350, prop=0.8)
car350_train = training(car350_split)
car350_test  = testing(car350_split)

k_grid = unique(round(exp(seq(log(332), log(2), length=300))))
rmse_grid_out = foreach(k = k_grid, .combine='c') %do% {
  knn_model = knnreg(price ~ mileage,
                     data = car350_train, k = k)
  modelr::rmse(knn_model, car350_test)
}

rmse_grid_out = data.frame(K = k_grid, RMSE = rmse_grid_out)

revlog_trans <- function(base = exp(1)) {
  require(scales)
  ## Define the desired transformation.
  trans <- function(x){
    -log(x, base)
  }
  ## Define the reverse of the desired transformation
  inv <- function(x){
    base^(-x)
  }
  ## Creates the transformation
  scales::trans_new(paste("revlog-", base, sep = ""),
                    trans,
                    inv,  ## The reverse of the transformation
                    log_breaks(base = base), ## default way to define the scale breaks
                    domain = c(1e-100, Inf) 
  )
}

p_out = ggplot(data=rmse_grid_out) + 
  theme_bw() + 
  geom_path(aes(x=K, y=RMSE, color='testset')) + 
  scale_x_continuous(trans=revlog_trans(base = 10)) 

ind_best = which.min(rmse_grid_out$RMSE)
k_best = k_grid[ind_best]

rmse_grid_in = foreach(k = k_grid, .combine='c') %do% {
  knn_model = knnreg(price ~ mileage,
                     data = car350_train, k = k)
  modelr::rmse(knn_model, car350_train)
}

rmse_grid_in = data.frame(K = k_grid, RMSE = rmse_grid_in)

p_out + geom_path(data=rmse_grid_in, aes(x=K, y=RMSE, color='trainset')) +
  scale_colour_manual(name="RMSE",
    values=c(testset="black", trainset="grey")) + 
  geom_vline(xintercept=k_best, color='darkgreen', size=1) + ggtitle("RMSE versus K-values (Mercedes S-Class 350)")

```

For K-values ranging from 2 to 332, the RMSE starts around 10,000 and goes up beyond 20,000. We find that the RMSE is minimized around 10,000 for a K-value between ~40 and ~10. For the purpose of this exercise, we can take the optimal K-value as 15 since it is less wiggly (lower variance) than that of lower K-values and still maintains a reatively low RMSE of around 9,500. 

### K-nearest neighbors: at the optimal K = 15  

```{r, fig.align='center', echo=FALSE, message=FALSE}
knn_model = knnreg(price ~ mileage,
                   data = car350_train, k = 15)

knn_pred = function(x) {
  predict(knn_model, newdata=data.frame(mileage=x))
}

p_base + stat_function(fun=knn_pred, color='red', size=1.5, n=1001) + ggtitle("RMSE for optimal value of K = 15 (Mercedes S-Class 350)")

modelr::rmse(knn_model, car350_test)
```
### Now for S-Class 65 AMG
``` {r knn65}

#Filter for 65 AMG
car65AMG <- sclass %>%
  filter(trim == '65 AMG')

#Split train/test for 65 
car65_split = initial_split(car65AMG, prop=0.8)
car65_train = training(car65_split)
car65_test  = testing(car65_split)

```

We can repeat our exercise of seeing how the model fits the training set and performance of our predictions for a few values of K.

###  K = 2 
```{r 65k2}
knn_model = knnreg(price ~ mileage, data=car65_train, k = 2) 
knn_pred = function(x) {
  predict(knn_model, newdata=data.frame(mileage=x))
}

p_base = ggplot(data = car65AMG) + 
  geom_point(mapping = aes(x = mileage, y = price), color='darkgrey') + 
  theme_bw(base_size=10) 
p_base + stat_function(fun=knn_pred, color='red', size=1.5, n=1001) + ggtitle("K = 2 (Mercedes S-Class 65 AMG)")

modelr::rmse(knn_model, car65_test)

```
We have an RMSE of nearly 29,000. 

### How about K = 5?
```{r 65k5}
knn_model = knnreg(price ~ mileage, data=car65_train, k = 5) 
knn_pred = function(x) {
  predict(knn_model, newdata=data.frame(mileage=x))
}

p_base + stat_function(fun=knn_pred, color='red', size=1.5, n=1001) + ggtitle("K = 5 (Mercedes S-Class 65 AMG)")

modelr::rmse(knn_model, car65_test)

```
Our RMSE falls to 26,420.

Let us see K = 10. 

### K=10
```{r 65k10}
knn_model = knnreg(price ~ mileage, data=car65_train, k = 10) 
knn_pred = function(x) {
  predict(knn_model, newdata=data.frame(mileage=x))
}

p_base + stat_function(fun=knn_pred, color='red', size=1.5, n=1001)

modelr::rmse(knn_model, car65_test)

```


### K = 20
```{r 65k20}
knn_model = knnreg(price ~ mileage, data=car65_train, k = 20) 
knn_pred = function(x) {
  predict(knn_model, newdata=data.frame(mileage=x))
}

p_base + stat_function(fun=knn_pred, color='red', size=1.5, n=1001) + ggtitle("K = 10 (Mercedes S-Class 65 AMG)")

modelr::rmse(knn_model, car65_test)

```
Our RMSE is now about 25,000. Let us plot RMSE against different values of K now. 

### What is our RMSE against different values of K?

```{r fig.align='center', message=FALSE, warning=FALSE}
#Split train/test for 65 
car65_split = initial_split(car65AMG, prop=0.8)
car65_train = training(car65_split)
car65_test  = testing(car65_split)

k_grid = unique(round(exp(seq(log(233), log(2), length=200))))
rmse_grid_out = foreach(k = k_grid, .combine='c') %do% {
  knn_model = knnreg(price ~ mileage,
                     data = car65_train, k = k)
  modelr::rmse(knn_model, car65_test)
}

rmse_grid_out = data.frame(K = k_grid, RMSE = rmse_grid_out)

p_out = ggplot(data=rmse_grid_out) + 
  theme_bw(base_size = 10) + 
  geom_path(aes(x=K, y=RMSE, color='testset')) + 
  scale_x_continuous(trans=revlog_trans(base = 10)) 

ind_best = which.min(rmse_grid_out$RMSE)
k_best = k_grid[ind_best]

rmse_grid_in = foreach(k = k_grid, .combine='c') %do% {
  knn_model = knnreg(price ~ mileage,
                     data = car65_train, k = k)
  modelr::rmse(knn_model, car65_train)
}

rmse_grid_in = data.frame(K = k_grid, RMSE = rmse_grid_in)

p_out + geom_path(data=rmse_grid_in, aes(x=K, y=RMSE, color='trainset')) +
  scale_colour_manual(name="RMSE",
    values=c(testset="black", trainset="grey")) + 
  geom_vline(xintercept=k_best, color='darkgreen', size=1) + ggtitle("RMSE versus K-values (Mercedes S-Class 65 AMG)")

```


For K-values ranging from 2 to 233, the RMSE starts around 30,000 and goes up beyond 80,000. We find that the RMSE is minimized around 20,000 for a K-value between ~30 and ~20. For the purpose of this exercise, we can take the optimal K-value as 9 since it is less wiggly (lower variance) than that of lower K-values and still maintains a reatively low RMSE of around 20,000. 


### K-nearest neighbors: at the optimal K = 9  

```{r fig.align='center', message=FALSE}
knn_model = knnreg(price ~ mileage,
                   data = car65_train, k = 9)

knn_pred = function(x) {
  predict(knn_model, newdata=data.frame(mileage=x))
}

p_base + stat_function(fun=knn_pred, color='red', size=1.5, n=1001) + ggtitle("RMSE for optimal value of K = 9 (Mercedes S-Class 65 AMG)")

modelr::rmse(knn_model, car65_test)
```

We can see that the trim level of 65 AMG has an optimal K of 9. On the other hand, the 350 trim has an optimal k value of 15. When we have a higher k-value, we will tend to have a higher bias but lower variance. Prices for cars with the 350 trim level vary less than that of cars with the 65 AMG level. Cars with the 350 trim are mostly clustered between 0 to 50000 miles for a price range between \$50,000 and \$75,000 or below $25,000 when offering mileage between 50,000 and 1,50,000 miles. Here, a higher k-value would be reasonable since we have lower variance within the dataset to be concerned about. 

With a lower k-value, we risk having a higher variance but lower bias. Cars with a 65 AMG level trim are more scattered, and therefore, we will need a lower k-value to make more accurate price predictions. 

While both trim levels are marketed as "luxury", the S65 AMG has features of a sports car and thus, will call a varying price on the second-hand market. Its price will hinge upon additional features and aspects such as year of production. Its working condition will be more critically evaluated than that of a standard sedan. In this case, that is the S350. S65 AMGs with 0 mileage cost between $20,000 to \$2,50,000 while S350 only vary between \$75,0000 and \$100,000 (approximately) for the same. It may also explain why we have a smaller set of observations for the S65 since there potentially would be a smaller market for a sports car than that for a sedan. 

When we check the RMSE for both datasets through K-cross validation with five folds, we can also see that the RMSE for S65 AMG is higher than that of S350. The mean RMSE for S350 is 11,353 and that for S65 AMG is 35,438. 

### Mean RMSE for S350
```{r, S350}
K_folds = 5

# Pipeline 1:
# create specific fold IDs for each row
# the default behavior of sample actually gives a permutation
Kcar350 = car350 %>%
  mutate(fold_id = rep(1:K_folds, length=nrow(car350)) %>% sample)

# now loop over folds
rmse_cv = foreach(fold = 1:K_folds, .combine='c') %do% {
  knn100 = knnreg(price ~ mileage,
                  data=filter(Kcar350, fold_id != fold), k=100)
  modelr::rmse(knn100, data=filter(Kcar350, fold_id == fold))
}

summary(rmse_cv)
mean(rmse_cv)  # mean CV error
sd(rmse_cv)/sqrt(K_folds)   # approximate standard error of CV error

```
### Mean RMSE for S65 AMG
```{r, 65AMG}
K_folds = 5

# Pipeline 1:
# create specific fold IDs for each row
# the default behavior of sample actually gives a permutation
Kcar65 = car65AMG %>%
  mutate(fold_id = rep(1:K_folds, length=nrow(car65AMG)) %>% sample)

# now loop over folds
rmse_cv = foreach(fold = 1:K_folds, .combine='c') %do% {
  knn100 = knnreg(price ~ mileage,
                  data=filter(Kcar65, fold_id != fold), k=100)
  modelr::rmse(knn100, data=filter(Kcar65, fold_id == fold))
}

summary(rmse_cv)

```

---
title: "Exercise 3"
author: "Soo Jee Choi, Annie Nguyen, and Tarini Sudhakar"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(rpart)
library(rpart.plot)
library(rsample) 
library(randomForest)
library(modelr)
```

## What causes what?

### ***1. Why can’t I just get data from a few different cities and run the regression of “Crime” on “Police” to understand how more cops in the streets affect crime? (“Crime” refers to some measure of crime rate and “Police” measures the number of cops in a city.)***

### High-crime cities have an incentive to hire more cops in an effort to lower crime rate. So it is likely the case that cities with high crime have more cops. That is, high crime rate is likely correlated with higher number of city cops. However, to isolate the causal effect of the number of cops on crime rate, one cannot simply run a regression of “Crime” on “Police” using data from a few cities. First, to find any causal effect, one needs to establish a large, robust data set to run analysis on. This is because we often get bias estimates using a smaller number of data sets. Second, there are other variables, such as region and area income, that have an effect on "Crime" that the regression would not be controlling for. This would cause the results to have omitted variable bias.


### ***2. How were the researchers from UPenn able to isolate this effect? Briefly describe their approach and discuss their result in “Table 2” from the researchers' paper.***

### The podcast discussed a clever way researchers looked into finding the causal effect of “Crime” on “Police” in Washington D.C. Washington D.C., being the nation's capital, has a terrorism alert system. When the terror alert level goes to orange, extra police are put on the Mall and other parts of Washington, irrespective of the day's crime rate. So researchers analyzed orange alert days (when there are extra police on the streets for reasons unrelated to street crime), to examine what happens to street crime. The researchers also looked at ridership levels on the Metro system on those particular days, as it is possible people were less likely to travel and tourists were less likely to visit Washington D.C. on Orange Alert days. However, Metro ridership levels actually were not diminished on high-terror days, so they suggested the number of crime-victims was largely unchanged.

### As seen in Table 2 Column 1, the researchers found that street crime went down on days when there were extra-police (for days when there was an orange alert level- i.e. reasons unrelated to street crime). The estimated coefficient of "High Alert" was negative (-7.316) and statistically significant at 5%. Column 2 additionally controls for metro midday ridership."High Alert" had a negative estimated coefficient (-6.046) and "Log(midday ridership)" had a positive estimated coefficient (17.341). Both estimates were statistically significant at 5% and 1%, respectively.


### ***3. Why did they have to control for Metro ridership? What was that trying to capture?***

### As stated in question 2, Metro ridership was added to the model to capture any potential differences in the number of potential "crime-victims" on alert level orange days. If the number of regular civilians (i.e. potential "crime-victims") - here being measured by Metro ridership - are notably different/lower on alert level Orange Days, then differences in crime rate may not only be attributed to changes in police presence, but also to changes in the number of civilians as well. However, the results in Table 2 show that that was not the case, and suggest the number of victims was largely unchanged.

### ***4. Can you describe the model being estimated in the first column of "Table 4"? What is the conclusion?***

### Table 4 shows a model where the dependent variable is the daily total number of crimes in D.C. and the independent variables are a "High Alert" "District 1" interaction term, "High Alert" "Other Districts" interaction term, and a "Log(midday ridership)" term. "District 1" refers to a dummy variable associated with crime incidents in the first police district area (which is the closest police district to the United States Capitol). Interactions terms are used when the effect of an independent variable on a dependent variable is context-specific. This model has separate "High Alert" interaction terms for "District 1" and "Other Districts". This allows the researchers to compare the effect of "High Alert"x"District 1" and "High Alert"x"Other Districts". And we do see evidence there is a difference - the estimated coefficients for "High Alert"x"District 1" and "High Alert"x"Other Districts" were -2.621 and -.571, respectively. We see that daily total number of crimes decreased more in District 1 on High Alert days than in Other Districts on High Alert days. Further, the results were significant at 1% for the "High Alert"x"District 1" term and not significant for the "High Alert"x"Other Districts" term. And as seen in Table 2, we see Log(midday ridership) is positive and statistically significant, indicating the number of Metro riders/potential crime victims were not diminished on high-terror days.


## Tree Modeling: Dengue Cases


```{r}

```


## Predictive Model Building: Green Certification

In this section we build a model to predict revenue per square foot per calendar year. We will use the model to quantify the average change in rental income per square foot associated with green certification.

Revenue is calculated by multiplying `Rent` with `lease_rate`. When revenue is added into the data set, we drop `Rent` and `lease_rate` to avoid collinearity. The variables we will be working with is as follows:

```{r echo=FALSE}
greenbuildings <- read.csv("greenbuildings.csv")
greenbuildings <- greenbuildings %>% mutate(revenue = Rent*leasing_rate)
data <- greenbuildings %>% select(-Energystar, -LEED, -leasing_rate, -Rent, -CS_PropertyID)
head(data)
set.seed(100)
load_split = initial_split(data, prop = 0.8)
load_train = training(load_split)
load_test = testing(load_split)
```

### Methods

#### Linear Regression

First, we will start with a linear regression model to use as a baseline for comparison. 
This model includes the following variables: 

```{r echo=FALSE}
lm_model <- lm(revenue ~ ., data = load_train)
coef(lm_model)
cat("RMSE for regression with step-wise selection: ", rmse(lm_model, load_test))
```


#### Regression with Step-wise Selection

Now, we will try step-wise selection to see if we can better refine the model.

```{r include=FALSE}
lm_step <- step(lm_model, scope=~(.)^2)
```

```{r echo=FALSE}
cat("RMSE for regression with step-wise selection: ", rmse(lm_step, load_test))
```

After applying step-wise selection, we see that the RMSE has been reduced, which means that the model is better refined. However, this new model has a total of 60 variables, which is not an efficient model to make predictions. We will see if there are other methods to more effectively predict revenue.


#### Tree Model
We will try comparing the tree model and the random forest model to the baseline model to see which model is better at predicting revenue per square foot.

```{r echo=FALSE}
load.tree = rpart(revenue ~ .,
                  data=load_train, control = rpart.control(cp = 0.00001))
cat("RMSE for tree: ", modelr::rmse(load.tree, load_test))
```



#### Random Forest Model

```{r echo=FALSE}
# fitting random forest
load.forest = randomForest(revenue ~ ., data = load_train, importance = TRUE, na.action=na.roughfix)
plot(load.forest)
cat("RMSE for random forest: ", modelr::rmse(load.forest, load_test))
```

Of the three models (baseline linear regression, tree, and random forest models), we see that the random forest model's RMSE is significantly lower and is better at predicting revenue per square foot per year. Therefore, we will use this model for prediction.



```{r echo=FALSE}
# variance importance plot
vi = varImpPlot(load.forest, type=1)
# partial dependence functions
partialPlot(load.forest, load_test, 'green_rating', las=1)
```

The above partial dependence plot shows the change in revenue per square foot associated with green certification, holding all other features constant. The slope for the graph is approximately 80, which shows that the average change in rental income per square foot associated with green certification is approximately $80.


### Conclusion

In this section, we went through a model-building process to find the best model to predict revenue per square foot per calendar year. Of the models that we have tested, we find that a random forest model does the best job of making predictions in an efficient manner, giving us the lowest RMSE value. We, then, used the model to find the average change in income per square foot associated with green certification by producing a partial dependence plot.



## Predictive Model Building: California Housing

```{r}

```


---
title: "Exercise 3"
author: "Soo Jee Choi, Annie Nguyen, and Tarini Sudhakar"
date: "`r Sys.Date()`"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE,
	cache = TRUE
)
library(Hmisc)
library(readr)
library(randomForest)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(rsample) 
library(lubridate)
library(modelr)
library(stringr)
library(viridis)
library(sf)
library(scales) 
library(Metrics)
library(dplyr)
library(mosaic)
library(gbm)
library(tidycensus)
library(foreach)
library(caret)
library(parallel)
```

## 1. What causes what?

#### ***1. Why can’t I just get data from a few different cities and run the regression of “Crime” on “Police” to understand how more cops in the streets affect crime? (“Crime” refers to some measure of crime rate and “Police” measures the number of cops in a city.)***

High-crime cities have an incentive to hire more cops in an effort to lower crime rate. So it is likely the case that cities with high crime have more cops. That is, high crime rate is likely correlated with higher number of city cops. However, to isolate the causal effect of the number of cops on crime rate, one cannot simply run a regression of “Crime” on “Police” using data from a few cities. First, to find any causal effect, one needs to establish a large, robust data set to run analysis on. This is because we often get bias estimates using a smaller number of data sets. Second, there are other variables, such as region and area income, that have an effect on "Crime" that the regression would not be controlling for. This would cause the results to have omitted variable bias.


#### ***2. How were the researchers from UPenn able to isolate this effect? Briefly describe their approach and discuss their result in “Table 2” from the researchers' paper.***

The podcast discussed a clever way researchers looked into finding the causal effect of “Crime” on “Police” in Washington D.C. Washington D.C., being the nation's capital, has a terrorism alert system. When the terror alert level goes to orange, extra police are put on the Mall and other parts of Washington, irrespective of the day's crime rate. So researchers analyzed orange alert days (when there are extra police on the streets for reasons unrelated to street crime), to examine what happens to street crime. The researchers also looked at ridership levels on the Metro system on those particular days, as it is possible people were less likely to travel and tourists were less likely to visit Washington D.C. on Orange Alert days. However, Metro ridership levels actually were not diminished on high-terror days, so they suggested the number of crime-victims was largely unchanged.

As seen in Table 2 Column 1, the researchers found that street crime went down on days when there were extra-police (for days when there was an orange alert level- i.e. reasons unrelated to street crime). The estimated coefficient of "High Alert" was negative (-7.316) and statistically significant at 5%. Column 2 additionally controls for metro midday ridership."High Alert" had a negative estimated coefficient (-6.046) and "Log(midday ridership)" had a positive estimated coefficient (17.341). Both estimates were statistically significant at 5% and 1%, respectively.


#### ***3. Why did they have to control for Metro ridership? What was that trying to capture?***

As stated in question 2, Metro ridership was added to the model to capture any potential differences in the number of potential "crime-victims" on alert level orange days. If the number of regular civilians (i.e. potential "crime-victims") - here being measured by Metro ridership - are notably different/lower on alert level Orange Days, then differences in crime rate may not only be attributed to changes in police presence, but also to changes in the number of civilians as well. However, the results in Table 2 show that that was not the case, and suggest the number of victims was largely unchanged.

#### ***4. Can you describe the model being estimated in the first column of "Table 4"? What is the conclusion?***

Table 4 shows a model where the dependent variable is the daily total number of crimes in D.C. and the independent variables are a "High Alert" "District 1" interaction term, "High Alert" "Other Districts" interaction term, and a "Log(midday ridership)" term. "District 1" refers to a dummy variable associated with crime incidents in the first police district area (which is the closest police district to the United States Capitol). Interactions terms are used when the effect of an independent variable on a dependent variable is context-specific. This model has separate "High Alert" interaction terms for "District 1" and "Other Districts". This allows the researchers to compare the effect of "High Alert"x"District 1" and "High Alert"x"Other Districts". And we do see evidence there is a difference - the estimated coefficients for "High Alert"x"District 1" and "High Alert"x"Other Districts" were -2.621 and -.571, respectively. We see that daily total number of crimes decreased more in District 1 on High Alert days than in Other Districts on High Alert days. Further, the results were significant at 1% for the "High Alert"x"District 1" term and not significant for the "High Alert"x"Other Districts" term. And as seen in Table 2, we see Log(midday ridership) is positive and statistically significant, indicating the number of Metro riders/potential crime victims were not diminished on high-terror days.


## 2. Tree Modeling: Dengue Cases

Our aim is to use CART, random forests, and gradient-boosted trees to predict dengue cases in San Juan, Puerto Rico and Iquitos, Peru using weekly data from 1990 to 2010. Our data set contains the six feature variables explicitly listed (total_cases, city, season, specific_humidity, tdtr_k, precipitation_amt) in addition to the variables measuring average temperature and dew point temperature in kelvin (i.e. avg_temp_k and dew_point_temp_k, respectively). The city and season variables are set as factors as we want the analysis to treat the variable values as a category.

```{r Prepare dataset}
dengue = read.csv("dengue.csv")

# Create factors
city = factor(dengue$city)
season = factor(dengue$season)

# Create new data frame with dummy variables incorporated
dengue_dataset <- data.frame(city = city,
                     season = season,
                     total_cases = dengue$total_cases,
                     specific_humidity = dengue$specific_humidity,
                     avg_diurnal_temp_range = dengue$tdtr_k,
                     precipitation_amt = dengue$precipitation_amt,
                     avg_temp_k = dengue$avg_temp_k,
                     dew_point_temp_k = dengue$dew_point_temp_k)
```
The data set is split into training and testing sets. We build our basic CART model with the control cp = 0.00001 and the the five feature variables explicitly listed to predict the number of dengue cases (city, season, specific_humidity, tdtr_k, precipitation_amt). With the option cp = 0.00001, the CART model "grows big" by splitting a node if the split improves the deviance by a factor of 0.00001 (0.001%). Then the tree is pruned to the smallest tree whose CV error is within 1 standard deviation of the minimum.

We consider combinations of two additional features (average temperature and dew point temperature in kelvin) to find the best CART model. We consider four models: the basic CART model (the model consisting of the five explicitly listed independent variables), the basic CART model with the avg_temp_k variable, the basic CART model with the dew_point_temp_k variable, and the basic CART model with both the avg_temp_k and dew_point_temp_k variables. We evaluate the quality of the models by examining the average in-sample RMSE for 25 model train/test splits for each model. We find that the basic CART model with both the avg_temp_k and dew_point_temp_k variables is the best CART model with an average RMSE of 37.774. The basic CART model, the basic CART model with the avg_temp_k variable, and the basic CART model with the dew_point_temp_k variables had average RMSE values of 40.38013, 39.82441, and 40.1219, respectively.

  ***Basic CART model***

```{r Basic CART}
# CART Model
load_split = initial_split(dengue_dataset, prop=0.8)
load_train = training(load_split)
load_test  = testing(load_split)

load.tree = rpart(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt,
                  data=load_train, control = rpart.control(cp = 0.00001))

rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split = initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  load.tree = update(load.tree, data=load_train)
  
  # Function for picking the smallest tree whose CV error is within 1 std err of the minimum
  cp_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  cp_opt}
  
  # Selecting the tree
  cp_1se(load.tree)

  # Function pruning the tree at that level
  prune_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  prune(my_tree, cp=cp_opt)}

  # Pruning tree at the 1se complexity level
  load.tree_prune = prune_1se(load.tree)
  
  # Calculate RMSE
  modelr::rmse(load.tree_prune, load_train)}
colMeans(rmse_simulation)
```

  ***Basic CART model with average temperature***
```{r Avg Temp CART}
# CART Model
load.tree = rpart(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + avg_temp_k,
                  data=load_train, control = rpart.control(cp = 0.00001))

rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split = initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  load.tree = update(load.tree, data=load_train)
  
  # Function for picking the smallest tree whose CV error is within 1 std err of the minimum
  cp_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  cp_opt}
  
  # Selecting the tree
  cp_1se(load.tree)

  # Function pruning the tree at that level
  prune_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  prune(my_tree, cp=cp_opt)}

  # Pruning tree at the 1se complexity level
  load.tree_prune = prune_1se(load.tree)
  
  # Calculate RMSE
  modelr::rmse(load.tree_prune, load_train)}
colMeans(rmse_simulation)
```

  ***Basic CART model with dew point*** 
```{r Dew Point CART}
# CART Model
load.tree = rpart(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + dew_point_temp_k,
                  data=load_train, control = rpart.control(cp = 0.00001))

rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split = initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  load.tree = update(load.tree, data=load_train)
  
  # Function for picking the smallest tree whose CV error is within 1 std err of the minimum
  cp_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  cp_opt}
  
  # Selecting the tree
  cp_1se(load.tree)

  # Function pruning the tree at that level
  prune_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  prune(my_tree, cp=cp_opt)}

  # Pruning tree at the 1se complexity level
  load.tree_prune = prune_1se(load.tree)
  
  # Calculate RMSE
  modelr::rmse(load.tree_prune, load_train)}
colMeans(rmse_simulation)
```

  ***Basic CART Model with average temperature and dew point***
```{r Avg Temp and Dew Point CART}
# CART Model
load.tree = rpart(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + avg_temp_k + dew_point_temp_k,
                  data=load_train, control = rpart.control(cp = 0.00001))

rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split = initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  load.tree = update(load.tree, data=load_train)
  
  # Function for picking the smallest tree whose CV error is within 1 std err of the minimum
  cp_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  cp_opt}
  
  # Selecting the tree
  cp_1se(load.tree)

  # Function pruning the tree at that level
  prune_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  prune(my_tree, cp=cp_opt)}

  # Pruning tree at the 1se complexity level
  load.tree_prune = prune_1se(load.tree)
  
  # Calculate RMSE
  modelr::rmse(load.tree_prune, load_train)}
colMeans(rmse_simulation)
```

For Random Forests, we again consider combinations of two additional features (average temperature and dew point temperature in kelvin) to find the best Random Forests model. We consider the following four models: the basic model (the model consisting of the five explicitly listed independent variables), the basic model with the avg_temp_k variable, the basic model with the dew_point_temp_k variable, and the basic model with both the avg_temp_k and dew_point_temp_k variables. The quality of the models are evaluated by examining the average in-sample RMSE for 25 model train/test splits for each model. 

Similar to the best CART model, we find that the basic Random Forest model with both the avg_temp_k and dew_point_temp_k variables is the best model with an average RMSE of 21.48982. Thebasic Random Forest model, the basic Random Forest model with the avg_temp_k variable, and the basic Random Forest model with the dew_point_temp_k variables had average RMSE values of 34.70102, 22.35256, and 22.8386, respectively.

  ***Basic Random Forests***
```{r Basic Random Forest}
rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split =  initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  # Random forest
  load.forest = randomForest(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt,
                             data=load_train, na.action=na.exclude)
  
  # Calculate RMSE
  modelr::rmse(load.forest, load_train)}
colMeans(rmse_simulation)
```

  ***Basic Random Forests with average temperature***
```{r Avg Temp Random Forest}
rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split =  initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  # Random forest
  load.forest = randomForest(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + avg_temp_k,
                             data=load_train, na.action=na.exclude)
  
  # Calculate RMSE
  modelr::rmse(load.forest, load_train)}
colMeans(rmse_simulation)
```

  ***Basic Random Forests with dew point***
```{r Dew Point Random Forest}
rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split =  initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  # Random forest
  load.forest = randomForest(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + dew_point_temp_k,
                             data=load_train, na.action=na.exclude)
  
  # Calculate RMSE
  modelr::rmse(load.forest, load_train)}
colMeans(rmse_simulation)
```

  ***Basic Random Forests with average temperature and dew point***
```{r Avg Temp and Dew Point Random Forest}
rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split =  initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  # Random forest
  load.forest = randomForest(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + avg_temp_k + dew_point_temp_k,
                             data=load_train, na.action=na.exclude)
  
  # Calculate RMSE
  modelr::rmse(load.forest, load_train)}
colMeans(rmse_simulation)
```

Finally, for the Gradient-Boosted Trees model we again consider combinations of two additional features (average temperature and dew point temperature in kelvin) to find the best Gradient-Boosted Trees model. The model we used utilized the default Gaussian model). We examine the four models we have been considering before (the basic model, the basic model with the avg_temp_k variable, the basic model with the dew_point_temp_k variable, and the basic model with both the avg_temp_k and dew_point_temp_k variables). The quality of the models are evaluated by examining the average in-sample RMSE for 25 model train/test splits for each model. 

Similar to the best CART model and the best Random Forest model, we find that the basic Gradient-Boosted Trees model with both the avg_temp_k and dew_point_temp_k variables is the best model with an average RMSE of 17.46581. The the basic Gradient-Boosted Trees model, the basic Gradient-Boosted Trees model with the avg_temp_k variable, and the basic Gradient-Boosted Trees model with the dew_point_temp_k variables had average RMSE values of 20.83645, 19.07204, and 20.20074, respectively.

  ***Basic Gradient-Boosted Trees*** 
```{r Basic Gaussian Gradient-Boosted Trees, message=FALSE}
rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split =  initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  # Gradient-Boosted Trees
  boost = gbm(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt, 
               data = load_train, distribution='gaussian', interaction.depth=4, n.trees=1500, shrinkage=.05)
  
  # Calculate RMSE
  modelr::rmse(boost, load_train)}
colMeans(rmse_simulation)
```

  ***Basic Gradient-Boosted Trees with average temperature***
```{r Avg Temp Gaussian Gradient-Boosted Trees, message=FALSE}
rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split =  initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  # Gradient-Boosted Trees
  boost = gbm(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + avg_temp_k, 
               data = load_train, distribution='gaussian', interaction.depth=4, n.trees=1500, shrinkage=.05)
  
  # Calculate RMSE
  modelr::rmse(boost, load_train)}
colMeans(rmse_simulation)
```
  
  ***Basic Gradient-Boosted Trees with dew point***
```{r Dew Point Gaussian Gradient-Boosted Trees, message=FALSE}
rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split =  initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  # Gradient-Boosted Trees
  boost = gbm(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + dew_point_temp_k, 
               data = load_train, distribution='gaussian', interaction.depth=4, n.trees=1500, shrinkage=.05)
  
  # Calculate RMSE
  modelr::rmse(boost, load_train)}
colMeans(rmse_simulation)
```

  ***Basic Gradient-Boosted Trees with average temperature and dew point***
```{r Avg Temp and Dew Point Gaussian Gradient-Boosted Trees, message=FALSE}
rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split =  initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  # Gradient-Boosted Trees
  boost = gbm(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + avg_temp_k + dew_point_temp_k, 
               data = load_train, distribution='gaussian', interaction.depth=4, n.trees=1500, shrinkage=.05)
  
  # Calculate RMSE
  modelr::rmse(boost, load_train)}
colMeans(rmse_simulation)
```

We now use the best CART model, Random Forests model, and Gradient-Boosted Trees model to predict the total number of dengue cases. For all three models, we found that the best models, by measure of in-sample RMSE, were the basic model with both the avg_temp_k and dew_point_temp_k variables. We compare the three models by using the testing data as a final check to see which model performed the best. Like with the previous model analysis, the quality of the models are evaluated by examining the average of 25 model train/test splits for each model. We find that the Random Forest model performed the best with an out-of-sample RMSE of 39.64522. The CART model did second best with an out-of-sample RMSE of 40.1887 and the Gradient-Boosted Trees model did the worst with an out-of-sample RMSE of 41.38736.

```{r Comparing Using the Testing Set, message=FALSE}
# Empty vectors to store results
cart = c()
randomForest = c()
gradientBoost = c()

# Simulate 25 times
rmse_simulation = do(25)*{
  # Split data into training and testing sets
  load_split =  initial_split(dengue_dataset, prop=0.8)
  load_train = training(load_split)
  load_test  = testing(load_split)
  
  ## CART
  load.tree = rpart(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + dew_point_temp_k,
                  data=load_train, control = rpart.control(cp = 0.00001))
  
  # Function for picking the smallest tree whose CV error is within 1 std err of the minimum
  cp_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  cp_opt}
  
  # Selecting the tree
  cp_1se(load.tree)

  # Function pruning the tree at that level
  prune_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  prune(my_tree, cp=cp_opt)}

  # Pruning tree at the 1se complexity level
  load.tree_prune = prune_1se(load.tree)
  
  ## Random forest
  load.forest = randomForest(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + avg_temp_k + dew_point_temp_k,
                             data=load_train, na.action=na.exclude)
  
  ## Gradient-Boosted Trees
  boost = gbm(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + avg_temp_k + dew_point_temp_k, 
               data = load_train, distribution='gaussian', interaction.depth=4, n.trees=1500, shrinkage=.05)
  
  # Calculate RMSE
  cart = c(cart, modelr::rmse(load.tree_prune, load_test))
  randomForest = c(randomForest, modelr::rmse(load.forest, load_test))
  gradientBoost = c(gradientBoost, modelr::rmse(boost, load_test))}
simulation_results = data.frame(cart, randomForest, gradientBoost)
colMeans(simulation_results)
```

Partial dependent plots shows the relationship between total cases and an independent variable in our random forest model while taking account of the joint effect of other features. In the specific_humidity partial dependent plot, we see that total cases slowly increases with specific humidity, then increases slightly at 15 before shooting up around a specific humidity of 19. The partial dependence plot of precipitation amount shows a different picture - total cases initial takes a huge drop and then rises up and down from 0-100 before slowing rising into a plateau. The avg_diurnal_temp_range partial dependent plot shows total cases rapidly decreases, with a few small rises in the 0 to 5 avg_diurnal_temp_range variable range. The partial dependent plots for specific_humidity, precipitation_amt, and avg_diurnal_temp_range are presented below.

```{r Partial Dependence Plots, message=FALSE}
# Random forest
load.forest = randomForest(total_cases ~ city + season + specific_humidity + avg_diurnal_temp_range + precipitation_amt + avg_temp_k + dew_point_temp_k, data=load_train, importance = TRUE, na.action=na.exclude)

# Partial dependence plots
p1=pdp::partial(load.forest, pred.var='specific_humidity', las=1)
plot(p1,type = "l", xlab = "specific_humidity", ylab = "Dengue Cases", main = "Predicted Dengue Cases Specific_humidity")

p2=pdp::partial(load.forest, pred.var='precipitation_amt', las=1)
plot(p2,type = "l", xlab = "precipitation_amt", ylab = "Dengue Cases", main = "Predicted Dengue Cases Precipitation_amt")

p3=pdp::partial(load.forest, pred.var='avg_diurnal_temp_range', las=1)
plot(p3,type = "l", xlab = "avg_diurnal_temp_range", ylab = "Dengue Cases", main = "Predicted Dengue Cases Avg_diurnal_temp_range")
```

## 3. Predictive Model Building: Green Certification

In this section we build a model to predict revenue per square foot per calendar year. We will use the model to quantify the average change in rental income per square foot associated with green certification.

Revenue is calculated by multiplying `Rent` with `lease_rate`. When revenue is added into the data set, we drop `Rent` and `lease_rate` to avoid collinearity. The variables we will be working with is as follows:

```{r echo=FALSE}
greenbuildings <- read.csv("greenbuildings.csv")
greenbuildings <- greenbuildings %>% mutate(revenue = Rent*leasing_rate)
data <- greenbuildings %>% select(-Energystar, -LEED, -leasing_rate, -Rent, -CS_PropertyID)
head(data)
set.seed(100)
load_split = initial_split(data, prop = 0.8)
load_train = training(load_split)
load_test = testing(load_split)
```

### Methods

#### Linear Regression

First, we will start with a linear regression model to use as a baseline for comparison. 
This model includes the following variables: 

```{r echo=FALSE}
lm_model <- lm(revenue ~ ., data = load_train, na.action=na.exclude)
coef(lm_model)
cat("RMSE for linear regression: ", modelr::rmse(lm_model, load_test))
```


#### Regression with Step-wise Selection

Now, we will try step-wise selection to see if we can better refine the model.

```{r include=FALSE}
lm_step <- step(lm_model, scope=~(.)^2, na.action=na.exclude)
```

```{r include=FALSE}
cat("RMSE for regression with step-wise selection: ", modelr::rmse(lm_step, load_test))
```

After applying step-wise selection, we see that the RMSE has been reduced, which means that the model is better refined. However, this new model has a total of 60 variables, which is not an efficient model to make predictions. We will see if there are other methods to more effectively predict revenue.


#### Tree Model
We will try comparing the tree model and the random forest model to the baseline model to see which model is better at predicting revenue per square foot.

```{r}
load.tree = rpart(revenue ~ .,
                  data=load_train, control = rpart.control(cp = 0.00001), na.action=na.exclude)
cat("RMSE for tree: ", modelr::rmse(load.tree, load_test))
```



#### Random Forest Model

```{r}
# fitting random forest
load.forest = randomForest(revenue ~ ., data = load_train, importance = TRUE, na.action=na.exclude)
plot(load.forest)
cat("RMSE for random forest: ", modelr::rmse(load.forest, load_test))
```

Of the three models (baseline linear regression, tree, and random forest models), we see that the random forest model's RMSE is significantly lower and is better at predicting revenue per square foot per year. Therefore, we will use this model for prediction.



```{r}
# variance importance plot
vi = varImpPlot(load.forest, type=1)
# partial dependence functions
partialPlot(load.forest, load_test, 'green_rating', las=1)
```

The above partial dependence plot shows the change in revenue per square foot associated with green certification, holding all other features constant. The slope for the graph is approximately 80, which shows that the average change in rental income per square foot associated with green certification is approximately $80.


### Conclusion
In this section, we went through a model-building process to find the best model to predict revenue per square foot per calendar year. Of the models that we have tested, we find that a random forest model does the best job of making predictions in an efficient manner, giving us the lowest RMSE value. We, then, used the model to find the average change in income per square foot associated with green certification by producing a partial dependence plot.


## 4. Predictive Model Building: California Housing
In this part of the assignment, we want to predict the median house value in California. We have 9 variables and 20640 observations. Since we have total rooms and bedrooms for households in the tract, we standardise these by households. You can find a description of the full dataset in the appendix. 

We use random forests to build our model (see appendix for its superior performance against linear model, K-nearest neighbours, and a single decision tree). What does random forests mean? Imagine an upside-down tree. Trees involves sequential mini-decisions that result in a choice or prediction. Random forests involve the creation of a large number of these decision trees, each of which is trained on a different subset of the available data. The algorithm randomly selects a subset of features to use for each tree, which prevents overfitting. 

Once the decision trees are trained, they can be used to make predictions on new data. Random forests combines the predictions from all of the decision trees to arrive at a final prediction. 

We first plot median house values on the map of California. We can see that the houses with the highest median value are clustered around the Bay Area and Los Angeles in California. This makes sense given that these are the technology and film industry hubs respectively, and there is high demand and limited supply of housing.

```{r}
CAhousing <- read_csv("CAhousing.csv")

#Standardise variables 
CAhousing <- CAhousing %>%
  mutate(avgRooms = totalRooms/households,
         avgBedrooms = totalBedrooms/households)

CAhousing = CAhousing[,-c(4,5)] 

#Creating the base map 
ca_df <- tigris::counties("CA")
ca_base <- ggplot(ca_df) +
  geom_sf(colour="black", fill="white")

#Plotting median house value on a map
house_map_1 = ca_base +
  geom_point(data = CAhousing, aes(x=longitude, y=latitude, color=`medianHouseValue`), alpha=0.4)+
  xlab("Longitude") + ylab("Latitude")+
  ggtitle("California: Median House Value") +
  scale_color_distiller(palette = "Paired", labels = comma) +
              labs(color = "Median House Value (in USD)") + 
  theme_void()

house_map_1
```

Now, before we run our models, we split our data into training and testing datasets in an 80-20 ratio. We first run our random forests model and get a Root Mean Squared Error (RMSE) of 51,322.64 on the training data. On the testing data, our RMSE is slightly higher at 52,016.37, which is expected. 

```{r include=FALSE}
#Splitting into training and testing data
CAhousing_split <- initial_split(CAhousing, prop. = 0.8)
CAhousing_train <- training(CAhousing_split)
CAhousing_test <- testing(CAhousing_split)

# now a random forest
CAhousing.forest = randomForest(medianHouseValue ~ .,
                           data=CAhousing_train, importance = TRUE)

CAhousing.forest$mse[length(CAhousing.forest$mse)]
cat("In-sample RMSE: ", sqrt(CAhousing.forest$mse[length(CAhousing.forest$mse)]))

pred <- predict(CAhousing.forest, CAhousing_test)
#sqrt(mean((CAhousing_test$medianHouseValue - pred)^2))

# let's compare RMSE on the test set
#modelr::rmse(CAhousing.forest, CAhousing_train)
cat("Out-of-sample RMSE: ", modelr::rmse(CAhousing.forest, CAhousing_test))

# shows out-of-bag MSE as a function of the number of trees used
#plot(CAhousing.forest)
```

Let us see how our predicted values from test data using random forests look on the map of California. There is now a slight decrease in the clear clustering of houses valued around $400,000 to \$500,000 that we could see with the actual data. 

```{r}
#Plotting predicted median house value on a map
pred_df <- data.frame(pred)

CAhousing2 <- cbind(CAhousing, pred_df)

house_map_2 = ca_base +
  geom_point(data = CAhousing2, aes(x=longitude, y=latitude, color=`pred`), alpha=0.4)+
  xlab("Longitude") + ylab("Latitude")+
  ggtitle("California: Predicted Median House Value") +
  scale_color_distiller(palette = "Paired", labels = comma) +
              labs(color = "Predicted Median House Value (in USD)") + 
  theme_void()

house_map_2
```

Let us look at the errors next. There seems to be a tendency to incorrectly estimate house value (generally undervalue) in counties that had higher median house values (around the Bay Area and Los Angeles).

```{r}
#Plotting errors for predicted median house value on a map
errors <- (CAhousing_test$medianHouseValue - pred)
#can also take (pred/actual)
#don't need to take log of the ratio 

errors <- data.frame(errors)

CAhousing3 <- cbind(CAhousing2, errors)

CA_tracts <- tigris::counties("CA")

house_map_3 = 
  ca_base + 
  geom_point(data = CAhousing3, aes(x=longitude, y=latitude, color=`errors`), alpha=0.4)+
  xlab("Longitude") + ylab("Latitude")+
  ggtitle("California: Residuals for Predicted Median House Value") +
  scale_color_distiller(palette = "Paired", labels = comma) +
              labs(color = "Residuals of predicted Median House Value (in USD)") + 
  theme_void()
house_map_3

```

### Appendix 

Appendix 1: California housing dataset
The dataset, after standardising, has the following variables.
```{r}
ls(CAhousing)
```

Appendix 2: Linear model 

By running the following linear model, we get an out-of-sample RMSE of 73,968.75 and in-sample RMSE of 72,045.72. This is much higher than that of random forests and tree models.  
```{r}
lm_CAhousing <- lm(medianHouseValue ~ housingMedianAge + population + medianIncome + avgBedrooms + avgRooms + latitude + longitude + medianIncome:avgBedrooms:avgRooms + avgRooms:population, data = CAhousing_train)

summary(lm_CAhousing)
```

```{r}
#In-sample
cat("In-sample RMSE: ",modelr::rmse(lm_CAhousing, CAhousing_train))
#Out-of-sample 
cat("Out-of-sample RMSE: ",modelr::rmse(lm_CAhousing, CAhousing_test))
```

Appendix 3: K-nearest neighbours 

We run the K-nearest neighbours for the following values of K: 10, 20, 30, 50, 75, and 100. Our out-of-sample RMSE for all values is above 100,000. 

```{r}
knn_model = knnreg(medianHouseValue ~ .,
                   data = CAhousing_train, k = 10)
cat("In-sample RMSE for K = 10: ", modelr::rmse(knn_model, CAhousing_train))
cat("Out-of-sample RMSE for K = 10: ", modelr::rmse(knn_model, CAhousing_test))

knn_model = knnreg(medianHouseValue ~ .,
                   data = CAhousing_train, k = 20)
cat("In-sample RMSE for K = 20: ", modelr::rmse(knn_model, CAhousing_train))
cat("Out-of-sample RMSE for K = 20: ",modelr::rmse(knn_model, CAhousing_test))

knn_model = knnreg(medianHouseValue ~ .,
                   data = CAhousing_train, k = 30)
cat("In-sample RMSE for K = 30: ", modelr::rmse(knn_model, CAhousing_train))
cat("Out-of-sample RMSE for K = 30: ",modelr::rmse(knn_model, CAhousing_test))

knn_model = knnreg(medianHouseValue ~ .,
                   data = CAhousing_train, k = 50)
cat("In-sample RMSE for K = 50: ", modelr::rmse(knn_model, CAhousing_train))
cat("Out-of-sample RMSE for K = 50: ", modelr::rmse(knn_model, CAhousing_test))

knn_model = knnreg(medianHouseValue ~ .,
                   data = CAhousing_train, k = 75)
cat("In-sample RMSE for K = 75: ", modelr::rmse(knn_model, CAhousing_train))
cat("Out-of-sample RMSE for K = 75: ",modelr::rmse(knn_model, CAhousing_test))

knn_model = knnreg(medianHouseValue ~ .,
                   data = CAhousing_train, k = 100)
cat("In-sample RMSE for K = 100: ", modelr::rmse(knn_model, CAhousing_train))
cat("Out-of-sample RMSE for K = 100: ",modelr::rmse(knn_model, CAhousing_test))
```

Appendix 4: Single Tree Model
When we run a single decision tree on the data, we get an out-of-sample RMSE of 61,469.24, much higher than that of random forests. 

```{r}
# let's fit a single tree
CAhousing.tree = rpart(medianHouseValue ~ .,
                  data=CAhousing_train, control = rpart.control(cp = 0.00001))

cat("In-sample RMSE: ", modelr::rmse(CAhousing.tree, CAhousing_train))
cat("Out-of-sample RMSE: ", modelr::rmse(CAhousing.tree, CAhousing_test))

```
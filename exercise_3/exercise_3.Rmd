---
title: "Exercise 3"
author: "Soo Jee Choi, Annie Nguyen, and Tarini Sudhakar"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(Hmisc)
library(readr)
library(randomForest)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(rsample) 
library(lubridate)
library(modelr)
library(ggmap)
library(mapdata)
library(maps)
library(stringr)
library(viridis)
library(sf)
library(scales) 
library(Metrics)


```

## What causes what?

### ***1. Why can’t I just get data from a few different cities and run the regression of “Crime” on “Police” to understand how more cops in the streets affect crime? (“Crime” refers to some measure of crime rate and “Police” measures the number of cops in a city.)***

### High-crime cities have an incentive to hire more cops in an effort to lower crime rate. So it is likely the case that cities with high crime have more cops. That is, high crime rate is likely correlated with higher number of city cops. However, to isolate the causal effect of the number of cops on crime rate, one cannot simply run a regression of “Crime” on “Police” using data from a few cities. First, to find any causal effect, one needs to establish a large, robust data set to run analysis on. This is because we often get bias estimates using a smaller number of data sets. Second, there are other variables, such as region and area income, that have an effect on "Crime" that the regression would not be controlling for. This would cause the results to have omitted variable bias.


### ***2. How were the researchers from UPenn able to isolate this effect? Briefly describe their approach and discuss their result in “Table 2” from the researchers' paper.***

### The podcast discussed a clever way researchers looked into finding the causal effect of “Crime” on “Police” in Washington D.C. Washington D.C., being the nation's capital, has a terrorism alert system. When the terror alert level goes to orange, extra police are put on the Mall and other parts of Washington, irrespective of the day's crime rate. So researchers analyzed orange alert days (when there are extra police on the streets for reasons unrelated to street crime), to examine what happens to street crime. The researchers also looked at ridership levels on the Metro system on those particular days, as it is possible people were less likely to travel and tourists were less likely to visit Washington D.C. on Orange Alert days. However, Metro ridership levels actually were not diminished on high-terror days, so they suggested the number of crime-victims was largely unchanged.

### As seen in Table 2 Column 1, the researchers found that street crime went down on days when there were extra-police (for days when there was an orange alert level- i.e. reasons unrelated to street crime). The estimated coefficient of "High Alert" was negative (-7.316) and statistically significant at 5%. Column 2 additionally controls for metro midday ridership."High Alert" had a negative estimated coefficient (-6.046) and "Log(midday ridership)" had a positive estimated coefficient (17.341). Both estimates were statistically significant at 5% and 1%, respectively.


### ***3. Why did they have to control for Metro ridership? What was that trying to capture?***

### As stated in question 2, Metro ridership was added to the model to capture any potential differences in the number of potential "crime-victims" on alert level orange days. If the number of regular civilians (i.e. potential "crime-victims") - here being measured by Metro ridership - are notably different/lower on alert level Orange Days, then differences in crime rate may not only be attributed to changes in police presence, but also to changes in the number of civilians as well. However, the results in Table 2 show that that was not the case, and suggest the number of victims was largely unchanged.

### ***4. Can you describe the model being estimated in the first column of "Table 4"? What is the conclusion?***

### Table 4 shows a model where the dependent variable is the daily total number of crimes in D.C. and the independent variables are a "High Alert" "District 1" interaction term, "High Alert" "Other Districts" interaction term, and a "Log(midday ridership)" term. "District 1" refers to a dummy variable associated with crime incidents in the first police district area (which is the closest police district to the United States Capitol). Interactions terms are used when the effect of an independent variable on a dependent variable is context-specific. This model has separate "High Alert" interaction terms for "District 1" and "Other Districts". This allows the researchers to compare the effect of "High Alert"x"District 1" and "High Alert"x"Other Districts". And we do see evidence there is a difference - the estimated coefficients for "High Alert"x"District 1" and "High Alert"x"Other Districts" were -2.621 and -.571, respectively. We see that daily total number of crimes decreased more in District 1 on High Alert days than in Other Districts on High Alert days. Further, the results were significant at 1% for the "High Alert"x"District 1" term and not significant for the "High Alert"x"Other Districts" term. And as seen in Table 2, we see Log(midday ridership) is positive and statistically significant, indicating the number of Metro riders/potential crime victims were not diminished on high-terror days.


## Tree Modeling: Dengue Cases


```{r}

```


## Predictive Model Building: Green Certification


```{r}

```


## Predictive Model Building: California Housing

Your task is to build the best predictive model you can for medianHouseValue, using the other available features. Write a short report detailing your methods. Make sure your report includes an estimate for the overall out-of-sample accuracy of your proposed model. Also include three figures:

  i. a plot of the original data, using a color scale to show medianHouseValue (or log medianHouseValue) versus longitude (x) and latitude (y).
  ii. a plot of your model's predictions of medianHouseValue (or log medianHouseValue) versus longitude (x) and latitude (y).
  iii. a plot of your model's errors/residuals (or log residuals) versus longitude (x) and latitude (y).
  
 
In this part of the assignment, we want to predict the median house value in California. We have 9 variables and 20640 observations. You can find a description of the dataset in the appendix. 

We use random forests to build our model (see appendix for comparison against linear model and K-nearest neighbours). What does that mean? Imagine an upside-down tree. Trees involves sequential mini-decisions that result in a choice or prediction. Random forests involve the creation of a large number of these decision trees, each of which is trained on a different subset of the available data. The algorithm randomly selects a subset of features to use for each tree, which prevents overfitting. 

Once the decision trees are trained, they can be used to make predictions on new data. Random forests combines the predictions from all of the decision trees to arrive at a final prediction. 

We first plot median house values on the map of California. We can see that there are clusters.
```{r}
CAhousing <- read_csv("~/Documents/Coding/eco395m-exercises/exercise_3/CAhousing.csv")

head(CAhousing)

#Plotting median house value as is 
#plot_map = ggplot(CAhousing, 
#                  aes(x = longitude, y = latitude, color = medianHouseValue)) +
#              geom_point(aes(size = population), alpha = 0.4) +
#              xlab("Longitude") +
#              ylab("Latitude") +
#              ggtitle("California: Median House Value") +
#              theme(plot.title = element_text(hjust = 0.5)) +
#              scale_color_distiller(palette = "Paired", labels = comma) +
#              labs(color = "Median House Value (in USD)", size = "Population") +
#  theme_void()
#plot_map

#Creating the base map 
ca_df<-subset(map_data("state"), region == "california")
ca_base <- ggplot(data = ca_df, mapping = aes(x = long, y = lat)) + 
  coord_fixed(1.3) + 
  geom_polygon(colour="black", fill="white")

#Plotting median house value on a map
house_map_1 = ca_base +
  geom_point(data = CAhousing, aes(x=longitude, y=latitude, color=`medianHouseValue`), alpha=0.4)+
  xlab("Longitude") + ylab("Latitude")+
  ggtitle("California: Median House Value") +
  scale_color_distiller(palette = "Paired", labels = comma) +
              labs(color = "Median House Value (in USD)") + 
  theme_void()

#Splitting into training and testing data

CAhousing_split <- initial_split(CAhousing, prop. = 0.8)
CAhousing_train <- training(CAhousing_split)
CAhousing_test <- testing(CAhousing_split)

```

```{r}
# let's fit a single tree
CAhousing.tree = rpart(medianHouseValue ~ .,
                  data=CAhousing_train, control = rpart.control(cp = 0.00001))

plot(CAhousing.tree, uniform = TRUE)
text(CAhousing.tree, cex=0.6)

# now a random forest
# notice: no tuning parameters!  just using the default
# downside: takes longer because we're fitting hundreds of trees (500 by default)
# the importance=TRUE flag tells randomForest to calculate variable importance metrics
CAhousing.forest = randomForest(medianHouseValue ~ .,
                           data=CAhousing_train, importance = TRUE)

CAhousing.forest$mse[length(CAhousing.forest$mse)]
sqrt(CAhousing.forest$mse[length(CAhousing.forest$mse)])

pred <- predict(CAhousing.forest, CAhousing_test)
sqrt(mean((CAhousing_test$medianHouseValue - pred)^2))

rmse_forest <- rmse(CAhousing_test$medianHouseValue, pred)

# shows out-of-bag MSE as a function of the number of trees used
plot(CAhousing.forest)

#Plotting predicted median house value on a map
pred_df <- data.frame(pred)

CAhousing2 <- cbind(CAhousing, pred_df)

house_map_2 = ca_base +
  geom_point(data = CAhousing2, aes(x=longitude, y=latitude, color=`pred`), alpha=0.4)+
  xlab("Longitude") + ylab("Latitude")+
  ggtitle("California: Predicted Median House Value") +
  scale_color_distiller(palette = "Paired", labels = comma) +
              labs(color = "Median House Value (in USD)") + 
  theme_void()

#Plotting errors for predicted median house value on a map
errors <- CAhousing_test$medianHouseValue - pred

errors <- data.frame(errors)

CAhousing3 <- cbind(CAhousing2, errors)

house_map_3 = ca_base +
  geom_point(data = CAhousing3, aes(x=longitude, y=latitude, color=`errors`), alpha=0.4)+
  xlab("Longitude") + ylab("Latitude")+
  ggtitle("California: Residuals for Predicted Median House Value") +
  scale_color_distiller(palette = "Paired", labels = comma) +
              labs(color = "Median House Value (in USD)") + 
  theme_void()


# let's compare RMSE on the test set
modelr::rmse(CAhousing.tree, CAhousing_test)
modelr::rmse(CAhousing.forest, CAhousing_test)  # a lot lower!


```

